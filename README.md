# CSV Massive Data Analyzer

Una herramienta web para analizar datasets CSV masivos (hasta 90GB+) sin cargar los datos completos en memoria.

## Caracter√≠sticas

- **An√°lisis de datasets masivos**: Maneja m√∫ltiples archivos CSV grandes sin problemas de memoria
- **Motor optimizado**: DuckDB con procesamiento paralelo, 8 threads y 4GB de memoria
- **Conteo r√°pido**: Cuenta millones de filas en segundos sin cargar datos
- **Smart Sampling**: Muestreo inteligente para datasets grandes (visualizaci√≥n instant√°nea)
- **Extracci√≥n autom√°tica de fechas**: Lee la fecha del nombre del archivo y la agrega como columna
- **Filtros din√°micos**: Filtra por fechas, columnas espec√≠ficas y valores
- **Presets de filtros**: Guarda y carga configuraciones de filtros frecuentes
- **Operaciones optimizadas**: Todas las agregaciones se hacen en DuckDB (sin cargar datos en memoria)
  - Suma, conteo, promedio, m√≠nimo, m√°ximo calculados sobre el dataset completo
  - Agrupaciones con visualizaciones autom√°ticas
- **Visualizaciones interactivas**: Gr√°ficos de l√≠neas, barras, pastel, series temporales
- **Exportaci√≥n flexible**: Descarga hasta 10 millones de filas filtradas

## Requisitos

- **Python 3.8 o superior**
- Windows (los scripts de instalaci√≥n est√°n dise√±ados para Windows)
- Conexi√≥n a internet (solo para instalaci√≥n)

## Instalaci√≥n

### Paso 1: Verificar Python

Abre PowerShell o Command Prompt y verifica que Python est√© instalado:

```bash
python --version
```

Si no tienes Python instalado, desc√°rgalo desde: https://www.python.org/downloads/

**Importante**: Durante la instalaci√≥n de Python, marca la opci√≥n "Add Python to PATH"

### Paso 2: Instalar la aplicaci√≥n

1. Descarga o clona este proyecto en tu computadora
2. Abre la carpeta del proyecto en el explorador de archivos
3. Haz doble clic en `instalar.bat`
4. Espera a que termine la instalaci√≥n (puede tomar unos minutos)

## Uso

### Iniciar la aplicaci√≥n

1. Haz doble clic en `ejecutar.bat`
2. La aplicaci√≥n se abrir√° autom√°ticamente en tu navegador
3. Para detener la aplicaci√≥n, presiona `Ctrl+C` en la ventana de comandos

### Usar la interfaz

1. **Seleccionar carpeta de datos**
   - En la barra lateral, ingresa la ruta completa a la carpeta que contiene tus archivos CSV
   - Ejemplo: `C:\Users\TuUsuario\Documents\datos_csv`

2. **Seleccionar columnas**
   - Marca las columnas que quieres analizar
   - Por defecto se muestran las primeras 5 columnas

3. **Aplicar filtros (opcional)**
   - **Filtro por fechas**: Selecciona un rango de fechas
   - **Filtros por columna**: 
     - Selecciona las columnas que quieres filtrar
     - Escribe los valores manualmente, separados por comas
     - Ejemplo: `1, 2, 3` o `A01, A02, A03`
   - **Guardar preset**: Guarda tu configuraci√≥n de filtros para usarla despu√©s

4. **Configurar la query**
   - **Max rows to load**: Define cu√°ntas filas cargar (por defecto 50,000)
   - **Smart Sampling**: Activa para datasets grandes - carga una muestra representativa
   - **Importante**: Puedes cambiar columnas y filtros SIN ejecutar la query todav√≠a

5. **Ejecutar la query**
   - Haz clic en el bot√≥n **‚ñ∂Ô∏è RUN QUERY** en la barra lateral
   - Los datos se cargan UNA SOLA VEZ y se cachean en memoria
   - El bot√≥n muestra "‚ö†Ô∏è" si cambias la configuraci√≥n (necesitas re-ejecutar)

6. **Explorar los datos cacheados (R√ÅPIDO - sin queries adicionales)**
   - **Pesta√±a "Data View"**: Visualiza los datos cargados
   - **Pesta√±a "Visualizations"**: Crea gr√°ficos interactivos
   - **Pesta√±a "Operations"**: Realiza operaciones matem√°ticas instant√°neas
   - **Pesta√±a "Export"**: Exporta los datos cargados a CSV o Excel

### Presets de filtros

Los presets te permiten guardar configuraciones de filtros que uses frecuentemente:

1. Aplica los filtros que desees
2. En la barra lateral, expande "Save Current Filters as Preset"
3. Escribe un nombre para tu preset y haz clic en "Save Preset"
4. Para cargar un preset, selecci√≥nalo del men√∫ desplegable "Load Preset"
5. Para eliminar un preset, selecci√≥nalo y haz clic en el √≠cono de papelera üóëÔ∏è

## Ejemplos de uso

### An√°lisis b√°sico
1. Selecciona las columnas de inter√©s
2. Ve a la pesta√±a "Operations"
3. Selecciona "Summary Statistics" para ver estad√≠sticas descriptivas

### Crear visualizaciones
1. Aplica los filtros necesarios
2. Ve a la pesta√±a "Visualizations"
3. Selecciona el tipo de gr√°fico que deseas
4. Configura los ejes y columnas

### Exportar datos filtrados
1. Aplica todos los filtros necesarios
2. Ve a la pesta√±a "Export"
3. Define cu√°ntas filas quieres exportar
4. Haz clic en "Generate CSV for Download"
5. Descarga el archivo CSV

## Tecnolog√≠as utilizadas

- **Streamlit**: Interfaz web interactiva
- **DuckDB**: Motor de consultas anal√≠ticas que lee CSV sin cargarlos en memoria
- **Pandas**: Manipulaci√≥n de datos
- **Plotly**: Visualizaciones interactivas

## Soluci√≥n de problemas

### "Python is not installed or not in PATH"
- Aseg√∫rate de tener Python instalado
- Durante la instalaci√≥n de Python, marca "Add Python to PATH"
- Reinicia tu computadora despu√©s de instalar Python

### "Virtual environment not found"
- Ejecuta `instalar.bat` primero antes de usar `ejecutar.bat`

### La aplicaci√≥n no se abre en el navegador
- Espera unos segundos despu√©s de ejecutar `ejecutar.bat`
- Si no se abre autom√°ticamente, copia la URL que aparece en la consola (generalmente `http://localhost:8501`)
- P√©gala en tu navegador

### Errores al leer los archivos CSV
- Verifica que la ruta a la carpeta sea correcta
- Aseg√∫rate de que los archivos tengan extensi√≥n `.csv`
- Verifica que tengas permisos de lectura en la carpeta

### Los filtros no funcionan
- Verifica que los valores est√©n escritos correctamente
- Aseg√∫rate de usar comas para separar m√∫ltiples valores
- Los valores son case-sensitive (distinguen may√∫sculas/min√∫sculas)

## Optimizaciones de Rendimiento

Esta herramienta est√° altamente optimizada para manejar millones de filas:

### üöÄ Estrategias de Optimizaci√≥n

1. **Procesamiento Paralelo**: DuckDB utiliza 8 threads para procesar datos simult√°neamente
2. **Conteo R√°pido**: Muestra el total de filas que coinciden con los filtros en segundos (sin cargar datos)
3. **Smart Sampling**: Para datasets > 1,000,000 filas, ofrece muestreo aleatorio autom√°tico
   - Visualiza 100,000 filas representativas de millones en segundos
   - El muestreo es configurable (10K - 10M filas)
4. **Agregaciones R√°pidas**: Todas las operaciones (SUM, AVG, COUNT, GROUP BY) se ejecutan sobre datos cacheados
   - Operaciones instant√°neas en memoria con Pandas
   - No hay queries adicionales despu√©s de cargar datos
5. **Filtros Manuales**: Entrada manual de valores para filtros - sin queries lentas de b√∫squeda
6. **Lectura Optimizada**: 
   - `parallel=true` en lectura de CSV
   - 8GB de memoria asignada a DuckDB
   - Uso de directorio temporal para operaciones grandes

### üí° Consejos para Mejor Rendimiento

- **Usa el bot√≥n RUN QUERY**: Carga los datos UNA SOLA VEZ - todas las operaciones y gr√°ficos usan los datos cacheados
- **Configura TODO antes de ejecutar**: Cambia columnas, filtros y l√≠mites SIN ejecutar queries innecesarias
- **Activa Smart Sampling** cuando trabajes con > 1 mill√≥n de filas para visualizaci√≥n
- **Operaciones son instant√°neas**: Todas las operaciones (suma, promedio, group by) trabajan sobre los datos ya cargados
- **Sin esperas al cambiar pesta√±as**: Data View, Visualizations, Operations y Export usan los mismos datos cacheados
- **Para datasets completos**: Carga las filas que necesites (hasta 10 millones) con RUN QUERY
- **Filtros manuales**: Escribe los valores directamente - no hay b√∫squedas autom√°ticas lentas

## Notas importantes

- La aplicaci√≥n no modifica tus archivos CSV originales
- Los datos se leen directamente desde disco, no se cargan completamente en memoria
- La vista de datos tiene un l√≠mite configurable (por defecto 50,000 filas) para evitar problemas de memoria en el navegador
- El l√≠mite de tama√±o de mensaje se ha configurado a 4 GB para manejar datasets grandes
- Los presets se guardan en `filter_presets.json` en la carpeta de la aplicaci√≥n
- DuckDB usa `temp_duckdb/` para operaciones temporales en disco
- **Rendimiento esperado**: 
  - Contar 10 millones de filas: 2-5 segundos
  - Sumar/Promediar 10 millones: 3-8 segundos
  - Agrupar y agregar: 5-15 segundos (dependiendo de cardinalidad)

## Soporte

Si encuentras alg√∫n problema o tienes preguntas, contacta al desarrollador del proyecto.

## Licencia

Este proyecto fue desarrollado para uso acad√©mico.

